<source>
  type forward
  port 24224
  bind 0.0.0.0
  time_format %Y-%m-%dT%H:%M:%S.%L%z
  tag docker.*
  format json
</source>

<source>
  type docker_metrics
  stats_interval 5s
  tag_prefix metrics
  #docker_socket unix:///var/run/docker.sock
  #docker_infos_path /var/lib/docker/execdriver/native
  #cgroup_path /sys/fs/cgroup
</source>

# Using filter to add container IDs to each event
<filter docker.var.lib.docker.containers.*.*.log>
  type record_transformer
  <record>
    container_id ${tag_parts[5]}
  </record>
</filter>

<match docker.**>
  type copy
#  <store>
#    type stdout
#    output_type json
#  </store>
  <store>
    type elasticsearch
    logstash_format true
    host "#{ENV['ES_IP']}" # dynamically configured to use Docker's link feature
    port 9200
    flush_interval 5s #debug
    #flush_interval 50s
    type_name log
    include_tag_key true
    buffer_type file
    buffer_path /tmp/fluent/es-buffer/es.all.*.buffer
    buffer_chunk_limit 250k
    retry_limit 5
    retry_wait 60
    num_threads 1
  </store>
</match>
<match metrics.**>
  type copy
  <store>
    type stdout
    output_type json
  </store>
  <store>
    type elasticsearch
    logstash_format true
    host "#{ENV['ES_IP']}" # dynamically configured to use Docker's link feature
    port 9200
    flush_interval 5s #debug
    type_name metrics
    include_tag_key true
  </store>
</match>
